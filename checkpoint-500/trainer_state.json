{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 500.0,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "grad_norm": 0.7272194623947144,
      "learning_rate": 0.0,
      "loss": 1.6678,
      "step": 1
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7210372686386108,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 1.6678,
      "step": 2
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7195749282836914,
      "learning_rate": 4.000000000000001e-06,
      "loss": 1.6675,
      "step": 3
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.7178144454956055,
      "learning_rate": 6e-06,
      "loss": 1.6668,
      "step": 4
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.7246457934379578,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.6658,
      "step": 5
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.719144344329834,
      "learning_rate": 1e-05,
      "loss": 1.6641,
      "step": 6
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.7195680141448975,
      "learning_rate": 1.2e-05,
      "loss": 1.662,
      "step": 7
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.7220417857170105,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 1.6596,
      "step": 8
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.7250520586967468,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.6568,
      "step": 9
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.7239127159118652,
      "learning_rate": 1.8e-05,
      "loss": 1.6534,
      "step": 10
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.7176101803779602,
      "learning_rate": 2e-05,
      "loss": 1.6497,
      "step": 11
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.7261422872543335,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 1.6454,
      "step": 12
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.7208229303359985,
      "learning_rate": 2.4e-05,
      "loss": 1.6408,
      "step": 13
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.7256653904914856,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 1.6355,
      "step": 14
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.7267881035804749,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 1.6299,
      "step": 15
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.7242538332939148,
      "learning_rate": 3e-05,
      "loss": 1.6236,
      "step": 16
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.7249389886856079,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 1.6167,
      "step": 17
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.7271994948387146,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 1.6092,
      "step": 18
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.733674943447113,
      "learning_rate": 3.6e-05,
      "loss": 1.6009,
      "step": 19
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.7313485145568848,
      "learning_rate": 3.8e-05,
      "loss": 1.5923,
      "step": 20
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.7307468056678772,
      "learning_rate": 4e-05,
      "loss": 1.5829,
      "step": 21
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.7348204255104065,
      "learning_rate": 4.2e-05,
      "loss": 1.5723,
      "step": 22
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.7386026978492737,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.5614,
      "step": 23
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.7437311410903931,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.5495,
      "step": 24
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.7466533780097961,
      "learning_rate": 4.8e-05,
      "loss": 1.5366,
      "step": 25
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.7548915147781372,
      "learning_rate": 5e-05,
      "loss": 1.5227,
      "step": 26
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.7601710557937622,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 1.5082,
      "step": 27
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.7690572142601013,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 1.4924,
      "step": 28
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.7808894515037537,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 1.4755,
      "step": 29
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.7955501079559326,
      "learning_rate": 5.8e-05,
      "loss": 1.457,
      "step": 30
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.812657356262207,
      "learning_rate": 6e-05,
      "loss": 1.4373,
      "step": 31
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.825738787651062,
      "learning_rate": 6.2e-05,
      "loss": 1.4173,
      "step": 32
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.8486587405204773,
      "learning_rate": 6.400000000000001e-05,
      "loss": 1.3939,
      "step": 33
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.8713477253913879,
      "learning_rate": 6.6e-05,
      "loss": 1.3698,
      "step": 34
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.8967017531394958,
      "learning_rate": 6.800000000000001e-05,
      "loss": 1.3441,
      "step": 35
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.92557293176651,
      "learning_rate": 7e-05,
      "loss": 1.3164,
      "step": 36
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.9583446383476257,
      "learning_rate": 7.2e-05,
      "loss": 1.2867,
      "step": 37
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.9895126819610596,
      "learning_rate": 7.4e-05,
      "loss": 1.2543,
      "step": 38
    },
    {
      "epoch": 39.0,
      "grad_norm": 1.0188696384429932,
      "learning_rate": 7.6e-05,
      "loss": 1.2218,
      "step": 39
    },
    {
      "epoch": 40.0,
      "grad_norm": 1.130733847618103,
      "learning_rate": 7.800000000000001e-05,
      "loss": 1.1876,
      "step": 40
    },
    {
      "epoch": 41.0,
      "grad_norm": 1.3768701553344727,
      "learning_rate": 8e-05,
      "loss": 1.1523,
      "step": 41
    },
    {
      "epoch": 42.0,
      "grad_norm": 1.5601036548614502,
      "learning_rate": 8.2e-05,
      "loss": 1.115,
      "step": 42
    },
    {
      "epoch": 43.0,
      "grad_norm": 1.5266363620758057,
      "learning_rate": 8.4e-05,
      "loss": 1.0742,
      "step": 43
    },
    {
      "epoch": 44.0,
      "grad_norm": 1.3496596813201904,
      "learning_rate": 8.6e-05,
      "loss": 1.0309,
      "step": 44
    },
    {
      "epoch": 45.0,
      "grad_norm": 1.2332912683486938,
      "learning_rate": 8.800000000000001e-05,
      "loss": 0.9872,
      "step": 45
    },
    {
      "epoch": 46.0,
      "grad_norm": 1.384582281112671,
      "learning_rate": 9e-05,
      "loss": 0.9426,
      "step": 46
    },
    {
      "epoch": 47.0,
      "grad_norm": 1.4324904680252075,
      "learning_rate": 9.200000000000001e-05,
      "loss": 0.8964,
      "step": 47
    },
    {
      "epoch": 48.0,
      "grad_norm": 1.3591605424880981,
      "learning_rate": 9.4e-05,
      "loss": 0.8505,
      "step": 48
    },
    {
      "epoch": 49.0,
      "grad_norm": 2.080261707305908,
      "learning_rate": 9.6e-05,
      "loss": 0.807,
      "step": 49
    },
    {
      "epoch": 50.0,
      "grad_norm": 2.2141542434692383,
      "learning_rate": 9.8e-05,
      "loss": 0.7626,
      "step": 50
    },
    {
      "epoch": 51.0,
      "grad_norm": 1.5085564851760864,
      "learning_rate": 0.0001,
      "loss": 0.7193,
      "step": 51
    },
    {
      "epoch": 52.0,
      "grad_norm": 2.181086778640747,
      "learning_rate": 0.00010200000000000001,
      "loss": 0.6788,
      "step": 52
    },
    {
      "epoch": 53.0,
      "grad_norm": 2.0017306804656982,
      "learning_rate": 0.00010400000000000001,
      "loss": 0.6372,
      "step": 53
    },
    {
      "epoch": 54.0,
      "grad_norm": 1.8184645175933838,
      "learning_rate": 0.00010600000000000002,
      "loss": 0.5952,
      "step": 54
    },
    {
      "epoch": 55.0,
      "grad_norm": 2.0624420642852783,
      "learning_rate": 0.00010800000000000001,
      "loss": 0.552,
      "step": 55
    },
    {
      "epoch": 56.0,
      "grad_norm": 1.7097502946853638,
      "learning_rate": 0.00011000000000000002,
      "loss": 0.5099,
      "step": 56
    },
    {
      "epoch": 57.0,
      "grad_norm": 1.7235442399978638,
      "learning_rate": 0.00011200000000000001,
      "loss": 0.4696,
      "step": 57
    },
    {
      "epoch": 58.0,
      "grad_norm": 1.6032222509384155,
      "learning_rate": 0.00011399999999999999,
      "loss": 0.4323,
      "step": 58
    },
    {
      "epoch": 59.0,
      "grad_norm": 1.641289234161377,
      "learning_rate": 0.000116,
      "loss": 0.398,
      "step": 59
    },
    {
      "epoch": 60.0,
      "grad_norm": 1.480683445930481,
      "learning_rate": 0.000118,
      "loss": 0.3674,
      "step": 60
    },
    {
      "epoch": 61.0,
      "grad_norm": 1.3267524242401123,
      "learning_rate": 0.00012,
      "loss": 0.3411,
      "step": 61
    },
    {
      "epoch": 62.0,
      "grad_norm": 1.1467663049697876,
      "learning_rate": 0.000122,
      "loss": 0.3206,
      "step": 62
    },
    {
      "epoch": 63.0,
      "grad_norm": 0.9696257710456848,
      "learning_rate": 0.000124,
      "loss": 0.3033,
      "step": 63
    },
    {
      "epoch": 64.0,
      "grad_norm": 0.9890631437301636,
      "learning_rate": 0.000126,
      "loss": 0.2873,
      "step": 64
    },
    {
      "epoch": 65.0,
      "grad_norm": 0.9145879149436951,
      "learning_rate": 0.00012800000000000002,
      "loss": 0.2721,
      "step": 65
    },
    {
      "epoch": 66.0,
      "grad_norm": 1.004172921180725,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.2565,
      "step": 66
    },
    {
      "epoch": 67.0,
      "grad_norm": 0.8219320178031921,
      "learning_rate": 0.000132,
      "loss": 0.2421,
      "step": 67
    },
    {
      "epoch": 68.0,
      "grad_norm": 0.7171669602394104,
      "learning_rate": 0.000134,
      "loss": 0.234,
      "step": 68
    },
    {
      "epoch": 69.0,
      "grad_norm": 0.5243991613388062,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.2271,
      "step": 69
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.5274935960769653,
      "learning_rate": 0.000138,
      "loss": 0.2209,
      "step": 70
    },
    {
      "epoch": 71.0,
      "grad_norm": 0.675345242023468,
      "learning_rate": 0.00014,
      "loss": 0.2158,
      "step": 71
    },
    {
      "epoch": 72.0,
      "grad_norm": 0.6721980571746826,
      "learning_rate": 0.000142,
      "loss": 0.2103,
      "step": 72
    },
    {
      "epoch": 73.0,
      "grad_norm": 0.5319297909736633,
      "learning_rate": 0.000144,
      "loss": 0.2044,
      "step": 73
    },
    {
      "epoch": 74.0,
      "grad_norm": 0.6660076379776001,
      "learning_rate": 0.000146,
      "loss": 0.1998,
      "step": 74
    },
    {
      "epoch": 75.0,
      "grad_norm": 0.5683686137199402,
      "learning_rate": 0.000148,
      "loss": 0.1935,
      "step": 75
    },
    {
      "epoch": 76.0,
      "grad_norm": 0.5072506070137024,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.1877,
      "step": 76
    },
    {
      "epoch": 77.0,
      "grad_norm": 0.492247611284256,
      "learning_rate": 0.000152,
      "loss": 0.1826,
      "step": 77
    },
    {
      "epoch": 78.0,
      "grad_norm": 0.5245753526687622,
      "learning_rate": 0.000154,
      "loss": 0.1772,
      "step": 78
    },
    {
      "epoch": 79.0,
      "grad_norm": 0.4858510494232178,
      "learning_rate": 0.00015600000000000002,
      "loss": 0.1716,
      "step": 79
    },
    {
      "epoch": 80.0,
      "grad_norm": 0.7574273943901062,
      "learning_rate": 0.00015800000000000002,
      "loss": 0.1661,
      "step": 80
    },
    {
      "epoch": 81.0,
      "grad_norm": 1.7430835962295532,
      "learning_rate": 0.00016,
      "loss": 0.163,
      "step": 81
    },
    {
      "epoch": 82.0,
      "grad_norm": 1.4557247161865234,
      "learning_rate": 0.000162,
      "loss": 0.1561,
      "step": 82
    },
    {
      "epoch": 83.0,
      "grad_norm": 1.3394988775253296,
      "learning_rate": 0.000164,
      "loss": 0.1503,
      "step": 83
    },
    {
      "epoch": 84.0,
      "grad_norm": 1.311368703842163,
      "learning_rate": 0.000166,
      "loss": 0.145,
      "step": 84
    },
    {
      "epoch": 85.0,
      "grad_norm": 0.8938034772872925,
      "learning_rate": 0.000168,
      "loss": 0.1384,
      "step": 85
    },
    {
      "epoch": 86.0,
      "grad_norm": 0.9271518588066101,
      "learning_rate": 0.00017,
      "loss": 0.1325,
      "step": 86
    },
    {
      "epoch": 87.0,
      "grad_norm": 2.1797409057617188,
      "learning_rate": 0.000172,
      "loss": 0.1301,
      "step": 87
    },
    {
      "epoch": 88.0,
      "grad_norm": 1.2718846797943115,
      "learning_rate": 0.000174,
      "loss": 0.1232,
      "step": 88
    },
    {
      "epoch": 89.0,
      "grad_norm": 1.655519962310791,
      "learning_rate": 0.00017600000000000002,
      "loss": 0.1188,
      "step": 89
    },
    {
      "epoch": 90.0,
      "grad_norm": 1.330834984779358,
      "learning_rate": 0.00017800000000000002,
      "loss": 0.1124,
      "step": 90
    },
    {
      "epoch": 91.0,
      "grad_norm": 1.1536110639572144,
      "learning_rate": 0.00018,
      "loss": 0.1078,
      "step": 91
    },
    {
      "epoch": 92.0,
      "grad_norm": 1.3547776937484741,
      "learning_rate": 0.000182,
      "loss": 0.1023,
      "step": 92
    },
    {
      "epoch": 93.0,
      "grad_norm": 2.0340752601623535,
      "learning_rate": 0.00018400000000000003,
      "loss": 0.0993,
      "step": 93
    },
    {
      "epoch": 94.0,
      "grad_norm": 1.38808012008667,
      "learning_rate": 0.00018600000000000002,
      "loss": 0.0928,
      "step": 94
    },
    {
      "epoch": 95.0,
      "grad_norm": 3.146332025527954,
      "learning_rate": 0.000188,
      "loss": 0.0928,
      "step": 95
    },
    {
      "epoch": 96.0,
      "grad_norm": 1.3139102458953857,
      "learning_rate": 0.00019,
      "loss": 0.0855,
      "step": 96
    },
    {
      "epoch": 97.0,
      "grad_norm": 3.373305559158325,
      "learning_rate": 0.000192,
      "loss": 0.0864,
      "step": 97
    },
    {
      "epoch": 98.0,
      "grad_norm": 2.36435866355896,
      "learning_rate": 0.000194,
      "loss": 0.0832,
      "step": 98
    },
    {
      "epoch": 99.0,
      "grad_norm": 3.77144455909729,
      "learning_rate": 0.000196,
      "loss": 0.0792,
      "step": 99
    },
    {
      "epoch": 100.0,
      "grad_norm": 2.7002949714660645,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.0771,
      "step": 100
    },
    {
      "epoch": 101.0,
      "grad_norm": 1.347874402999878,
      "learning_rate": 0.0002,
      "loss": 0.0697,
      "step": 101
    },
    {
      "epoch": 102.0,
      "grad_norm": 1.9214586019515991,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.0686,
      "step": 102
    },
    {
      "epoch": 103.0,
      "grad_norm": 2.840383529663086,
      "learning_rate": 0.000196,
      "loss": 0.0696,
      "step": 103
    },
    {
      "epoch": 104.0,
      "grad_norm": 1.5167922973632812,
      "learning_rate": 0.000194,
      "loss": 0.0629,
      "step": 104
    },
    {
      "epoch": 105.0,
      "grad_norm": 1.191402792930603,
      "learning_rate": 0.000192,
      "loss": 0.0585,
      "step": 105
    },
    {
      "epoch": 106.0,
      "grad_norm": 1.7138895988464355,
      "learning_rate": 0.00019,
      "loss": 0.0581,
      "step": 106
    },
    {
      "epoch": 107.0,
      "grad_norm": 1.0476018190383911,
      "learning_rate": 0.000188,
      "loss": 0.0537,
      "step": 107
    },
    {
      "epoch": 108.0,
      "grad_norm": 1.3341511487960815,
      "learning_rate": 0.00018600000000000002,
      "loss": 0.0521,
      "step": 108
    },
    {
      "epoch": 109.0,
      "grad_norm": 0.9749784469604492,
      "learning_rate": 0.00018400000000000003,
      "loss": 0.0492,
      "step": 109
    },
    {
      "epoch": 110.0,
      "grad_norm": 1.0872241258621216,
      "learning_rate": 0.000182,
      "loss": 0.0455,
      "step": 110
    },
    {
      "epoch": 111.0,
      "grad_norm": 1.119083046913147,
      "learning_rate": 0.00018,
      "loss": 0.0438,
      "step": 111
    },
    {
      "epoch": 112.0,
      "grad_norm": 1.2677780389785767,
      "learning_rate": 0.00017800000000000002,
      "loss": 0.0417,
      "step": 112
    },
    {
      "epoch": 113.0,
      "grad_norm": 1.0178519487380981,
      "learning_rate": 0.00017600000000000002,
      "loss": 0.0389,
      "step": 113
    },
    {
      "epoch": 114.0,
      "grad_norm": 1.3086720705032349,
      "learning_rate": 0.000174,
      "loss": 0.0382,
      "step": 114
    },
    {
      "epoch": 115.0,
      "grad_norm": 1.0084409713745117,
      "learning_rate": 0.000172,
      "loss": 0.0358,
      "step": 115
    },
    {
      "epoch": 116.0,
      "grad_norm": 1.223184585571289,
      "learning_rate": 0.00017,
      "loss": 0.0328,
      "step": 116
    },
    {
      "epoch": 117.0,
      "grad_norm": 1.3065309524536133,
      "learning_rate": 0.000168,
      "loss": 0.0337,
      "step": 117
    },
    {
      "epoch": 118.0,
      "grad_norm": 0.9319463968276978,
      "learning_rate": 0.000166,
      "loss": 0.0298,
      "step": 118
    },
    {
      "epoch": 119.0,
      "grad_norm": 1.176230788230896,
      "learning_rate": 0.000164,
      "loss": 0.0292,
      "step": 119
    },
    {
      "epoch": 120.0,
      "grad_norm": 0.965475857257843,
      "learning_rate": 0.000162,
      "loss": 0.0275,
      "step": 120
    },
    {
      "epoch": 121.0,
      "grad_norm": 0.7335986495018005,
      "learning_rate": 0.00016,
      "loss": 0.0263,
      "step": 121
    },
    {
      "epoch": 122.0,
      "grad_norm": 1.3946635723114014,
      "learning_rate": 0.00015800000000000002,
      "loss": 0.026,
      "step": 122
    },
    {
      "epoch": 123.0,
      "grad_norm": 0.5771130919456482,
      "learning_rate": 0.00015600000000000002,
      "loss": 0.0233,
      "step": 123
    },
    {
      "epoch": 124.0,
      "grad_norm": 1.2877118587493896,
      "learning_rate": 0.000154,
      "loss": 0.0237,
      "step": 124
    },
    {
      "epoch": 125.0,
      "grad_norm": 0.7153053879737854,
      "learning_rate": 0.000152,
      "loss": 0.0224,
      "step": 125
    },
    {
      "epoch": 126.0,
      "grad_norm": 0.8978650569915771,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.0217,
      "step": 126
    },
    {
      "epoch": 127.0,
      "grad_norm": 0.5291057229042053,
      "learning_rate": 0.000148,
      "loss": 0.0192,
      "step": 127
    },
    {
      "epoch": 128.0,
      "grad_norm": 0.5870333313941956,
      "learning_rate": 0.000146,
      "loss": 0.0191,
      "step": 128
    },
    {
      "epoch": 129.0,
      "grad_norm": 0.46294212341308594,
      "learning_rate": 0.000144,
      "loss": 0.0181,
      "step": 129
    },
    {
      "epoch": 130.0,
      "grad_norm": 0.43901145458221436,
      "learning_rate": 0.000142,
      "loss": 0.0177,
      "step": 130
    },
    {
      "epoch": 131.0,
      "grad_norm": 0.4252241253852844,
      "learning_rate": 0.00014,
      "loss": 0.0174,
      "step": 131
    },
    {
      "epoch": 132.0,
      "grad_norm": 0.6321209073066711,
      "learning_rate": 0.000138,
      "loss": 0.0163,
      "step": 132
    },
    {
      "epoch": 133.0,
      "grad_norm": 0.48493510484695435,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.0164,
      "step": 133
    },
    {
      "epoch": 134.0,
      "grad_norm": 0.45631375908851624,
      "learning_rate": 0.000134,
      "loss": 0.0153,
      "step": 134
    },
    {
      "epoch": 135.0,
      "grad_norm": 0.3292641043663025,
      "learning_rate": 0.000132,
      "loss": 0.0151,
      "step": 135
    },
    {
      "epoch": 136.0,
      "grad_norm": 0.4625461995601654,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.0149,
      "step": 136
    },
    {
      "epoch": 137.0,
      "grad_norm": 0.31797686219215393,
      "learning_rate": 0.00012800000000000002,
      "loss": 0.014,
      "step": 137
    },
    {
      "epoch": 138.0,
      "grad_norm": 0.3258208632469177,
      "learning_rate": 0.000126,
      "loss": 0.014,
      "step": 138
    },
    {
      "epoch": 139.0,
      "grad_norm": 0.28428101539611816,
      "learning_rate": 0.000124,
      "loss": 0.0133,
      "step": 139
    },
    {
      "epoch": 140.0,
      "grad_norm": 0.3049049377441406,
      "learning_rate": 0.000122,
      "loss": 0.0134,
      "step": 140
    },
    {
      "epoch": 141.0,
      "grad_norm": 0.44645124673843384,
      "learning_rate": 0.00012,
      "loss": 0.0133,
      "step": 141
    },
    {
      "epoch": 142.0,
      "grad_norm": 0.2805836796760559,
      "learning_rate": 0.000118,
      "loss": 0.013,
      "step": 142
    },
    {
      "epoch": 143.0,
      "grad_norm": 0.28159099817276,
      "learning_rate": 0.000116,
      "loss": 0.0125,
      "step": 143
    },
    {
      "epoch": 144.0,
      "grad_norm": 0.18804815411567688,
      "learning_rate": 0.00011399999999999999,
      "loss": 0.0128,
      "step": 144
    },
    {
      "epoch": 145.0,
      "grad_norm": 0.43228793144226074,
      "learning_rate": 0.00011200000000000001,
      "loss": 0.0123,
      "step": 145
    },
    {
      "epoch": 146.0,
      "grad_norm": 0.19538713991641998,
      "learning_rate": 0.00011000000000000002,
      "loss": 0.0118,
      "step": 146
    },
    {
      "epoch": 147.0,
      "grad_norm": 0.2437869757413864,
      "learning_rate": 0.00010800000000000001,
      "loss": 0.012,
      "step": 147
    },
    {
      "epoch": 148.0,
      "grad_norm": 0.2259449064731598,
      "learning_rate": 0.00010600000000000002,
      "loss": 0.0114,
      "step": 148
    },
    {
      "epoch": 149.0,
      "grad_norm": 0.18669509887695312,
      "learning_rate": 0.00010400000000000001,
      "loss": 0.0114,
      "step": 149
    },
    {
      "epoch": 150.0,
      "grad_norm": 0.21774117648601532,
      "learning_rate": 0.00010200000000000001,
      "loss": 0.0118,
      "step": 150
    },
    {
      "epoch": 151.0,
      "grad_norm": 0.14232765138149261,
      "learning_rate": 0.0001,
      "loss": 0.0108,
      "step": 151
    },
    {
      "epoch": 152.0,
      "grad_norm": 0.19310887157917023,
      "learning_rate": 9.8e-05,
      "loss": 0.0112,
      "step": 152
    },
    {
      "epoch": 153.0,
      "grad_norm": 0.15879777073860168,
      "learning_rate": 9.6e-05,
      "loss": 0.0112,
      "step": 153
    },
    {
      "epoch": 154.0,
      "grad_norm": 0.1816898137331009,
      "learning_rate": 9.4e-05,
      "loss": 0.0106,
      "step": 154
    },
    {
      "epoch": 155.0,
      "grad_norm": 0.1552693396806717,
      "learning_rate": 9.200000000000001e-05,
      "loss": 0.0105,
      "step": 155
    },
    {
      "epoch": 156.0,
      "grad_norm": 0.22096985578536987,
      "learning_rate": 9e-05,
      "loss": 0.0103,
      "step": 156
    },
    {
      "epoch": 157.0,
      "grad_norm": 0.20881928503513336,
      "learning_rate": 8.800000000000001e-05,
      "loss": 0.0107,
      "step": 157
    },
    {
      "epoch": 158.0,
      "grad_norm": 0.18236544728279114,
      "learning_rate": 8.6e-05,
      "loss": 0.0109,
      "step": 158
    },
    {
      "epoch": 159.0,
      "grad_norm": 0.23941175639629364,
      "learning_rate": 8.4e-05,
      "loss": 0.0108,
      "step": 159
    },
    {
      "epoch": 160.0,
      "grad_norm": 0.15217944979667664,
      "learning_rate": 8.2e-05,
      "loss": 0.0104,
      "step": 160
    },
    {
      "epoch": 161.0,
      "grad_norm": 0.1637687087059021,
      "learning_rate": 8e-05,
      "loss": 0.01,
      "step": 161
    },
    {
      "epoch": 162.0,
      "grad_norm": 0.1900208592414856,
      "learning_rate": 7.800000000000001e-05,
      "loss": 0.0107,
      "step": 162
    },
    {
      "epoch": 163.0,
      "grad_norm": 0.20120474696159363,
      "learning_rate": 7.6e-05,
      "loss": 0.0101,
      "step": 163
    },
    {
      "epoch": 164.0,
      "grad_norm": 0.17438732087612152,
      "learning_rate": 7.4e-05,
      "loss": 0.0104,
      "step": 164
    },
    {
      "epoch": 165.0,
      "grad_norm": 0.27537286281585693,
      "learning_rate": 7.2e-05,
      "loss": 0.0102,
      "step": 165
    },
    {
      "epoch": 166.0,
      "grad_norm": 0.10459758341312408,
      "learning_rate": 7e-05,
      "loss": 0.01,
      "step": 166
    },
    {
      "epoch": 167.0,
      "grad_norm": 0.15888828039169312,
      "learning_rate": 6.800000000000001e-05,
      "loss": 0.0096,
      "step": 167
    },
    {
      "epoch": 168.0,
      "grad_norm": 0.2664746642112732,
      "learning_rate": 6.6e-05,
      "loss": 0.0097,
      "step": 168
    },
    {
      "epoch": 169.0,
      "grad_norm": 0.11837661266326904,
      "learning_rate": 6.400000000000001e-05,
      "loss": 0.0097,
      "step": 169
    },
    {
      "epoch": 170.0,
      "grad_norm": 0.28291746973991394,
      "learning_rate": 6.2e-05,
      "loss": 0.0101,
      "step": 170
    },
    {
      "epoch": 171.0,
      "grad_norm": 0.1379404366016388,
      "learning_rate": 6e-05,
      "loss": 0.0096,
      "step": 171
    },
    {
      "epoch": 172.0,
      "grad_norm": 0.2337675839662552,
      "learning_rate": 5.8e-05,
      "loss": 0.0099,
      "step": 172
    },
    {
      "epoch": 173.0,
      "grad_norm": 0.1371784657239914,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 0.0098,
      "step": 173
    },
    {
      "epoch": 174.0,
      "grad_norm": 0.08914999663829803,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 0.0097,
      "step": 174
    },
    {
      "epoch": 175.0,
      "grad_norm": 0.16481101512908936,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 0.0096,
      "step": 175
    },
    {
      "epoch": 176.0,
      "grad_norm": 0.17304740846157074,
      "learning_rate": 5e-05,
      "loss": 0.0099,
      "step": 176
    },
    {
      "epoch": 177.0,
      "grad_norm": 0.1208108440041542,
      "learning_rate": 4.8e-05,
      "loss": 0.0094,
      "step": 177
    },
    {
      "epoch": 178.0,
      "grad_norm": 0.19057148694992065,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0094,
      "step": 178
    },
    {
      "epoch": 179.0,
      "grad_norm": 0.18116174638271332,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0095,
      "step": 179
    },
    {
      "epoch": 180.0,
      "grad_norm": 0.1699938178062439,
      "learning_rate": 4.2e-05,
      "loss": 0.0094,
      "step": 180
    },
    {
      "epoch": 181.0,
      "grad_norm": 0.16462358832359314,
      "learning_rate": 4e-05,
      "loss": 0.0094,
      "step": 181
    },
    {
      "epoch": 182.0,
      "grad_norm": 0.09144671261310577,
      "learning_rate": 3.8e-05,
      "loss": 0.0092,
      "step": 182
    },
    {
      "epoch": 183.0,
      "grad_norm": 0.13544104993343353,
      "learning_rate": 3.6e-05,
      "loss": 0.0093,
      "step": 183
    },
    {
      "epoch": 184.0,
      "grad_norm": 0.124076709151268,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0094,
      "step": 184
    },
    {
      "epoch": 185.0,
      "grad_norm": 0.11071857064962387,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0093,
      "step": 185
    },
    {
      "epoch": 186.0,
      "grad_norm": 0.12722697854042053,
      "learning_rate": 3e-05,
      "loss": 0.0093,
      "step": 186
    },
    {
      "epoch": 187.0,
      "grad_norm": 0.2191140353679657,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0095,
      "step": 187
    },
    {
      "epoch": 188.0,
      "grad_norm": 0.11421765387058258,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0089,
      "step": 188
    },
    {
      "epoch": 189.0,
      "grad_norm": 0.10485290735960007,
      "learning_rate": 2.4e-05,
      "loss": 0.0092,
      "step": 189
    },
    {
      "epoch": 190.0,
      "grad_norm": 0.15203432738780975,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0099,
      "step": 190
    },
    {
      "epoch": 191.0,
      "grad_norm": 0.19843028485774994,
      "learning_rate": 2e-05,
      "loss": 0.0092,
      "step": 191
    },
    {
      "epoch": 192.0,
      "grad_norm": 0.07285485416650772,
      "learning_rate": 1.8e-05,
      "loss": 0.0092,
      "step": 192
    },
    {
      "epoch": 193.0,
      "grad_norm": 0.12415336817502975,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0093,
      "step": 193
    },
    {
      "epoch": 194.0,
      "grad_norm": 0.07746009528636932,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0093,
      "step": 194
    },
    {
      "epoch": 195.0,
      "grad_norm": 0.14166350662708282,
      "learning_rate": 1.2e-05,
      "loss": 0.0092,
      "step": 195
    },
    {
      "epoch": 196.0,
      "grad_norm": 0.09202681481838226,
      "learning_rate": 1e-05,
      "loss": 0.009,
      "step": 196
    },
    {
      "epoch": 197.0,
      "grad_norm": 0.10362046211957932,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0093,
      "step": 197
    },
    {
      "epoch": 198.0,
      "grad_norm": 0.10722777247428894,
      "learning_rate": 6e-06,
      "loss": 0.0096,
      "step": 198
    },
    {
      "epoch": 199.0,
      "grad_norm": 0.12848415970802307,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.009,
      "step": 199
    },
    {
      "epoch": 200.0,
      "grad_norm": 0.06821949779987335,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.009,
      "step": 200
    },
    {
      "epoch": 201.0,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 3.025,
      "step": 201
    },
    {
      "epoch": 202.0,
      "grad_norm": NaN,
      "learning_rate": 3.93574297188755e-05,
      "loss": 3.0278,
      "step": 202
    },
    {
      "epoch": 203.0,
      "grad_norm": 44.22818374633789,
      "learning_rate": 3.855421686746988e-05,
      "loss": 3.0218,
      "step": 203
    },
    {
      "epoch": 204.0,
      "grad_norm": NaN,
      "learning_rate": 3.7751004016064253e-05,
      "loss": 2.9559,
      "step": 204
    },
    {
      "epoch": 205.0,
      "grad_norm": 42.59221649169922,
      "learning_rate": 3.694779116465863e-05,
      "loss": 2.9198,
      "step": 205
    },
    {
      "epoch": 206.0,
      "grad_norm": 47.11922073364258,
      "learning_rate": 3.614457831325301e-05,
      "loss": 2.6931,
      "step": 206
    },
    {
      "epoch": 207.0,
      "grad_norm": 49.99308776855469,
      "learning_rate": 3.534136546184739e-05,
      "loss": 2.4356,
      "step": 207
    },
    {
      "epoch": 208.0,
      "grad_norm": 45.12084197998047,
      "learning_rate": 3.4538152610441774e-05,
      "loss": 2.1006,
      "step": 208
    },
    {
      "epoch": 209.0,
      "grad_norm": 33.227752685546875,
      "learning_rate": 3.3734939759036146e-05,
      "loss": 1.8263,
      "step": 209
    },
    {
      "epoch": 210.0,
      "grad_norm": 20.23328971862793,
      "learning_rate": 3.2931726907630524e-05,
      "loss": 1.6107,
      "step": 210
    },
    {
      "epoch": 211.0,
      "grad_norm": 12.663859367370605,
      "learning_rate": 3.21285140562249e-05,
      "loss": 1.4715,
      "step": 211
    },
    {
      "epoch": 212.0,
      "grad_norm": 8.876136779785156,
      "learning_rate": 3.132530120481928e-05,
      "loss": 1.3825,
      "step": 212
    },
    {
      "epoch": 213.0,
      "grad_norm": 7.053086757659912,
      "learning_rate": 3.052208835341366e-05,
      "loss": 1.3184,
      "step": 213
    },
    {
      "epoch": 214.0,
      "grad_norm": 6.20229959487915,
      "learning_rate": 2.971887550200803e-05,
      "loss": 1.268,
      "step": 214
    },
    {
      "epoch": 215.0,
      "grad_norm": 5.955769062042236,
      "learning_rate": 2.891566265060241e-05,
      "loss": 1.2248,
      "step": 215
    },
    {
      "epoch": 216.0,
      "grad_norm": 5.554479122161865,
      "learning_rate": 2.8112449799196788e-05,
      "loss": 1.1847,
      "step": 216
    },
    {
      "epoch": 217.0,
      "grad_norm": 5.0884599685668945,
      "learning_rate": 2.7309236947791167e-05,
      "loss": 1.1496,
      "step": 217
    },
    {
      "epoch": 218.0,
      "grad_norm": 4.589449405670166,
      "learning_rate": 2.6506024096385545e-05,
      "loss": 1.1115,
      "step": 218
    },
    {
      "epoch": 219.0,
      "grad_norm": 4.075246334075928,
      "learning_rate": 2.570281124497992e-05,
      "loss": 1.0788,
      "step": 219
    },
    {
      "epoch": 220.0,
      "grad_norm": 3.694441080093384,
      "learning_rate": 2.48995983935743e-05,
      "loss": 1.0419,
      "step": 220
    },
    {
      "epoch": 221.0,
      "grad_norm": 3.4901857376098633,
      "learning_rate": 2.4096385542168677e-05,
      "loss": 1.0121,
      "step": 221
    },
    {
      "epoch": 222.0,
      "grad_norm": 3.4730238914489746,
      "learning_rate": 2.3293172690763055e-05,
      "loss": 0.9843,
      "step": 222
    },
    {
      "epoch": 223.0,
      "grad_norm": 3.512207508087158,
      "learning_rate": 2.248995983935743e-05,
      "loss": 0.9594,
      "step": 223
    },
    {
      "epoch": 224.0,
      "grad_norm": 3.5222136974334717,
      "learning_rate": 2.168674698795181e-05,
      "loss": 0.9348,
      "step": 224
    },
    {
      "epoch": 225.0,
      "grad_norm": 3.514009714126587,
      "learning_rate": 2.0883534136546184e-05,
      "loss": 0.909,
      "step": 225
    },
    {
      "epoch": 226.0,
      "grad_norm": 3.251710891723633,
      "learning_rate": 2.0080321285140562e-05,
      "loss": 0.8807,
      "step": 226
    },
    {
      "epoch": 227.0,
      "grad_norm": 3.0228872299194336,
      "learning_rate": 1.927710843373494e-05,
      "loss": 0.8582,
      "step": 227
    },
    {
      "epoch": 228.0,
      "grad_norm": 2.9249961376190186,
      "learning_rate": 1.8473895582329316e-05,
      "loss": 0.8336,
      "step": 228
    },
    {
      "epoch": 229.0,
      "grad_norm": 2.7392494678497314,
      "learning_rate": 1.7670682730923694e-05,
      "loss": 0.8149,
      "step": 229
    },
    {
      "epoch": 230.0,
      "grad_norm": 2.6686768531799316,
      "learning_rate": 1.6867469879518073e-05,
      "loss": 0.7929,
      "step": 230
    },
    {
      "epoch": 231.0,
      "grad_norm": 2.6910088062286377,
      "learning_rate": 1.606425702811245e-05,
      "loss": 0.7754,
      "step": 231
    },
    {
      "epoch": 232.0,
      "grad_norm": 2.566976547241211,
      "learning_rate": 1.526104417670683e-05,
      "loss": 0.7534,
      "step": 232
    },
    {
      "epoch": 233.0,
      "grad_norm": 2.575216293334961,
      "learning_rate": 1.4457831325301205e-05,
      "loss": 0.7349,
      "step": 233
    },
    {
      "epoch": 234.0,
      "grad_norm": 2.489741802215576,
      "learning_rate": 1.3654618473895583e-05,
      "loss": 0.7229,
      "step": 234
    },
    {
      "epoch": 235.0,
      "grad_norm": 2.457244873046875,
      "learning_rate": 1.285140562248996e-05,
      "loss": 0.7028,
      "step": 235
    },
    {
      "epoch": 236.0,
      "grad_norm": 2.4125359058380127,
      "learning_rate": 1.2048192771084338e-05,
      "loss": 0.687,
      "step": 236
    },
    {
      "epoch": 237.0,
      "grad_norm": 2.4468491077423096,
      "learning_rate": 1.1244979919678715e-05,
      "loss": 0.6746,
      "step": 237
    },
    {
      "epoch": 238.0,
      "grad_norm": 2.4153246879577637,
      "learning_rate": 1.0441767068273092e-05,
      "loss": 0.6625,
      "step": 238
    },
    {
      "epoch": 239.0,
      "grad_norm": 2.335580587387085,
      "learning_rate": 9.63855421686747e-06,
      "loss": 0.6496,
      "step": 239
    },
    {
      "epoch": 240.0,
      "grad_norm": 2.4076015949249268,
      "learning_rate": 8.835341365461847e-06,
      "loss": 0.638,
      "step": 240
    },
    {
      "epoch": 241.0,
      "grad_norm": 2.3376123905181885,
      "learning_rate": 8.032128514056226e-06,
      "loss": 0.6274,
      "step": 241
    },
    {
      "epoch": 242.0,
      "grad_norm": 2.3492109775543213,
      "learning_rate": 7.228915662650602e-06,
      "loss": 0.6159,
      "step": 242
    },
    {
      "epoch": 243.0,
      "grad_norm": 2.319425106048584,
      "learning_rate": 6.42570281124498e-06,
      "loss": 0.6074,
      "step": 243
    },
    {
      "epoch": 244.0,
      "grad_norm": 2.424954652786255,
      "learning_rate": 5.622489959839358e-06,
      "loss": 0.6002,
      "step": 244
    },
    {
      "epoch": 245.0,
      "grad_norm": 2.337404727935791,
      "learning_rate": 4.819277108433735e-06,
      "loss": 0.593,
      "step": 245
    },
    {
      "epoch": 246.0,
      "grad_norm": 2.318080425262451,
      "learning_rate": 4.016064257028113e-06,
      "loss": 0.5875,
      "step": 246
    },
    {
      "epoch": 247.0,
      "grad_norm": 2.3431568145751953,
      "learning_rate": 3.21285140562249e-06,
      "loss": 0.5797,
      "step": 247
    },
    {
      "epoch": 248.0,
      "grad_norm": 2.3580830097198486,
      "learning_rate": 2.4096385542168676e-06,
      "loss": 0.5775,
      "step": 248
    },
    {
      "epoch": 249.0,
      "grad_norm": 2.3798105716705322,
      "learning_rate": 1.606425702811245e-06,
      "loss": 0.5768,
      "step": 249
    },
    {
      "epoch": 250.0,
      "grad_norm": 2.385796546936035,
      "learning_rate": 8.032128514056225e-07,
      "loss": 0.5726,
      "step": 250
    },
    {
      "epoch": 251.0,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.0296,
      "step": 251
    },
    {
      "epoch": 252.0,
      "grad_norm": 50.07700729370117,
      "learning_rate": 1.7518248175182482e-05,
      "loss": 1.9581,
      "step": 252
    },
    {
      "epoch": 253.0,
      "grad_norm": 49.98212432861328,
      "learning_rate": 1.678832116788321e-05,
      "loss": 1.9926,
      "step": 253
    },
    {
      "epoch": 254.0,
      "grad_norm": 46.286888122558594,
      "learning_rate": 1.605839416058394e-05,
      "loss": 1.9345,
      "step": 254
    },
    {
      "epoch": 255.0,
      "grad_norm": 43.13782501220703,
      "learning_rate": 1.5328467153284673e-05,
      "loss": 1.8508,
      "step": 255
    },
    {
      "epoch": 256.0,
      "grad_norm": 37.450111389160156,
      "learning_rate": 1.45985401459854e-05,
      "loss": 1.755,
      "step": 256
    },
    {
      "epoch": 257.0,
      "grad_norm": 30.849958419799805,
      "learning_rate": 1.3868613138686131e-05,
      "loss": 1.6359,
      "step": 257
    },
    {
      "epoch": 258.0,
      "grad_norm": 27.172372817993164,
      "learning_rate": 1.3138686131386862e-05,
      "loss": 1.5923,
      "step": 258
    },
    {
      "epoch": 259.0,
      "grad_norm": 21.484390258789062,
      "learning_rate": 1.2408759124087593e-05,
      "loss": 1.4827,
      "step": 259
    },
    {
      "epoch": 260.0,
      "grad_norm": 19.683433532714844,
      "learning_rate": 1.1678832116788322e-05,
      "loss": 1.4271,
      "step": 260
    },
    {
      "epoch": 261.0,
      "grad_norm": 17.54902458190918,
      "learning_rate": 1.0948905109489052e-05,
      "loss": 1.38,
      "step": 261
    },
    {
      "epoch": 262.0,
      "grad_norm": 17.39999008178711,
      "learning_rate": 1.0218978102189781e-05,
      "loss": 1.3476,
      "step": 262
    },
    {
      "epoch": 263.0,
      "grad_norm": 15.685711860656738,
      "learning_rate": 9.48905109489051e-06,
      "loss": 1.2904,
      "step": 263
    },
    {
      "epoch": 264.0,
      "grad_norm": 14.123407363891602,
      "learning_rate": 8.759124087591241e-06,
      "loss": 1.2222,
      "step": 264
    },
    {
      "epoch": 265.0,
      "grad_norm": 14.097978591918945,
      "learning_rate": 8.02919708029197e-06,
      "loss": 1.193,
      "step": 265
    },
    {
      "epoch": 266.0,
      "grad_norm": 13.363805770874023,
      "learning_rate": 7.2992700729927e-06,
      "loss": 1.1564,
      "step": 266
    },
    {
      "epoch": 267.0,
      "grad_norm": 13.092845916748047,
      "learning_rate": 6.569343065693431e-06,
      "loss": 1.1225,
      "step": 267
    },
    {
      "epoch": 268.0,
      "grad_norm": 12.811319351196289,
      "learning_rate": 5.839416058394161e-06,
      "loss": 1.1021,
      "step": 268
    },
    {
      "epoch": 269.0,
      "grad_norm": 12.344602584838867,
      "learning_rate": 5.109489051094891e-06,
      "loss": 1.0792,
      "step": 269
    },
    {
      "epoch": 270.0,
      "grad_norm": 12.401885032653809,
      "learning_rate": 4.379562043795621e-06,
      "loss": 1.053,
      "step": 270
    },
    {
      "epoch": 271.0,
      "grad_norm": 12.00134563446045,
      "learning_rate": 3.64963503649635e-06,
      "loss": 1.0215,
      "step": 271
    },
    {
      "epoch": 272.0,
      "grad_norm": 12.343378067016602,
      "learning_rate": 2.9197080291970804e-06,
      "loss": 1.0263,
      "step": 272
    },
    {
      "epoch": 273.0,
      "grad_norm": 11.900481224060059,
      "learning_rate": 2.1897810218978103e-06,
      "loss": 0.9961,
      "step": 273
    },
    {
      "epoch": 274.0,
      "grad_norm": 11.606524467468262,
      "learning_rate": 1.4598540145985402e-06,
      "loss": 0.9981,
      "step": 274
    },
    {
      "epoch": 275.0,
      "grad_norm": 11.690991401672363,
      "learning_rate": 7.299270072992701e-07,
      "loss": 0.9839,
      "step": 275
    },
    {
      "epoch": 276.0,
      "grad_norm": 17.852401733398438,
      "learning_rate": 0.0,
      "loss": 1.2544,
      "step": 276
    },
    {
      "epoch": 277.0,
      "grad_norm": 17.043827056884766,
      "learning_rate": 4.2406876790830946e-05,
      "loss": 1.2579,
      "step": 277
    },
    {
      "epoch": 278.0,
      "grad_norm": 13.733929634094238,
      "learning_rate": 4.183381088825215e-05,
      "loss": 1.1115,
      "step": 278
    },
    {
      "epoch": 279.0,
      "grad_norm": 9.792924880981445,
      "learning_rate": 4.126074498567336e-05,
      "loss": 0.9912,
      "step": 279
    },
    {
      "epoch": 280.0,
      "grad_norm": 7.530529022216797,
      "learning_rate": 4.068767908309456e-05,
      "loss": 0.9207,
      "step": 280
    },
    {
      "epoch": 281.0,
      "grad_norm": 6.475011825561523,
      "learning_rate": 4.011461318051576e-05,
      "loss": 0.8629,
      "step": 281
    },
    {
      "epoch": 282.0,
      "grad_norm": 6.413857460021973,
      "learning_rate": 3.9541547277936964e-05,
      "loss": 0.8171,
      "step": 282
    },
    {
      "epoch": 283.0,
      "grad_norm": 6.915721893310547,
      "learning_rate": 3.896848137535817e-05,
      "loss": 0.7799,
      "step": 283
    },
    {
      "epoch": 284.0,
      "grad_norm": 6.166554927825928,
      "learning_rate": 3.839541547277937e-05,
      "loss": 0.7426,
      "step": 284
    },
    {
      "epoch": 285.0,
      "grad_norm": 5.194883823394775,
      "learning_rate": 3.782234957020058e-05,
      "loss": 0.7114,
      "step": 285
    },
    {
      "epoch": 286.0,
      "grad_norm": 3.9977309703826904,
      "learning_rate": 3.724928366762178e-05,
      "loss": 0.6749,
      "step": 286
    },
    {
      "epoch": 287.0,
      "grad_norm": 3.4664552211761475,
      "learning_rate": 3.667621776504298e-05,
      "loss": 0.6471,
      "step": 287
    },
    {
      "epoch": 288.0,
      "grad_norm": 3.2282447814941406,
      "learning_rate": 3.610315186246418e-05,
      "loss": 0.623,
      "step": 288
    },
    {
      "epoch": 289.0,
      "grad_norm": 3.000922441482544,
      "learning_rate": 3.553008595988539e-05,
      "loss": 0.5955,
      "step": 289
    },
    {
      "epoch": 290.0,
      "grad_norm": 2.962477207183838,
      "learning_rate": 3.4957020057306596e-05,
      "loss": 0.5701,
      "step": 290
    },
    {
      "epoch": 291.0,
      "grad_norm": 2.8592817783355713,
      "learning_rate": 3.4383954154727795e-05,
      "loss": 0.5493,
      "step": 291
    },
    {
      "epoch": 292.0,
      "grad_norm": 2.6932599544525146,
      "learning_rate": 3.3810888252148995e-05,
      "loss": 0.5261,
      "step": 292
    },
    {
      "epoch": 293.0,
      "grad_norm": 2.572777032852173,
      "learning_rate": 3.32378223495702e-05,
      "loss": 0.505,
      "step": 293
    },
    {
      "epoch": 294.0,
      "grad_norm": 2.4827001094818115,
      "learning_rate": 3.266475644699141e-05,
      "loss": 0.4822,
      "step": 294
    },
    {
      "epoch": 295.0,
      "grad_norm": 2.341472625732422,
      "learning_rate": 3.2091690544412614e-05,
      "loss": 0.4584,
      "step": 295
    },
    {
      "epoch": 296.0,
      "grad_norm": 2.468369483947754,
      "learning_rate": 3.151862464183381e-05,
      "loss": 0.4385,
      "step": 296
    },
    {
      "epoch": 297.0,
      "grad_norm": 2.508162021636963,
      "learning_rate": 3.0945558739255014e-05,
      "loss": 0.4166,
      "step": 297
    },
    {
      "epoch": 298.0,
      "grad_norm": 2.4595768451690674,
      "learning_rate": 3.037249283667622e-05,
      "loss": 0.3968,
      "step": 298
    },
    {
      "epoch": 299.0,
      "grad_norm": 2.38382887840271,
      "learning_rate": 2.9799426934097423e-05,
      "loss": 0.3757,
      "step": 299
    },
    {
      "epoch": 300.0,
      "grad_norm": 2.406888008117676,
      "learning_rate": 2.922636103151863e-05,
      "loss": 0.356,
      "step": 300
    },
    {
      "epoch": 301.0,
      "grad_norm": 2.4620704650878906,
      "learning_rate": 2.8653295128939826e-05,
      "loss": 0.3408,
      "step": 301
    },
    {
      "epoch": 302.0,
      "grad_norm": 2.596182346343994,
      "learning_rate": 2.8080229226361033e-05,
      "loss": 0.3187,
      "step": 302
    },
    {
      "epoch": 303.0,
      "grad_norm": 2.709970712661743,
      "learning_rate": 2.7507163323782236e-05,
      "loss": 0.2974,
      "step": 303
    },
    {
      "epoch": 304.0,
      "grad_norm": 2.4078128337860107,
      "learning_rate": 2.6934097421203442e-05,
      "loss": 0.279,
      "step": 304
    },
    {
      "epoch": 305.0,
      "grad_norm": 2.335925340652466,
      "learning_rate": 2.6361031518624642e-05,
      "loss": 0.2594,
      "step": 305
    },
    {
      "epoch": 306.0,
      "grad_norm": 2.671288013458252,
      "learning_rate": 2.5787965616045845e-05,
      "loss": 0.2415,
      "step": 306
    },
    {
      "epoch": 307.0,
      "grad_norm": 2.416293144226074,
      "learning_rate": 2.5214899713467048e-05,
      "loss": 0.2241,
      "step": 307
    },
    {
      "epoch": 308.0,
      "grad_norm": 2.823852777481079,
      "learning_rate": 2.4641833810888254e-05,
      "loss": 0.2081,
      "step": 308
    },
    {
      "epoch": 309.0,
      "grad_norm": 2.7655184268951416,
      "learning_rate": 2.4068767908309457e-05,
      "loss": 0.1902,
      "step": 309
    },
    {
      "epoch": 310.0,
      "grad_norm": 6.246867656707764,
      "learning_rate": 2.349570200573066e-05,
      "loss": 0.1831,
      "step": 310
    },
    {
      "epoch": 311.0,
      "grad_norm": 2.5330569744110107,
      "learning_rate": 2.2922636103151864e-05,
      "loss": 0.1619,
      "step": 311
    },
    {
      "epoch": 312.0,
      "grad_norm": 2.8757736682891846,
      "learning_rate": 2.2349570200573067e-05,
      "loss": 0.149,
      "step": 312
    },
    {
      "epoch": 313.0,
      "grad_norm": 2.482990026473999,
      "learning_rate": 2.177650429799427e-05,
      "loss": 0.1363,
      "step": 313
    },
    {
      "epoch": 314.0,
      "grad_norm": 2.624979019165039,
      "learning_rate": 2.1203438395415473e-05,
      "loss": 0.1255,
      "step": 314
    },
    {
      "epoch": 315.0,
      "grad_norm": 2.482973098754883,
      "learning_rate": 2.063037249283668e-05,
      "loss": 0.1133,
      "step": 315
    },
    {
      "epoch": 316.0,
      "grad_norm": 1.9470561742782593,
      "learning_rate": 2.005730659025788e-05,
      "loss": 0.1004,
      "step": 316
    },
    {
      "epoch": 317.0,
      "grad_norm": 1.7093374729156494,
      "learning_rate": 1.9484240687679085e-05,
      "loss": 0.0928,
      "step": 317
    },
    {
      "epoch": 318.0,
      "grad_norm": 1.668471336364746,
      "learning_rate": 1.891117478510029e-05,
      "loss": 0.0879,
      "step": 318
    },
    {
      "epoch": 319.0,
      "grad_norm": 1.244526982307434,
      "learning_rate": 1.833810888252149e-05,
      "loss": 0.079,
      "step": 319
    },
    {
      "epoch": 320.0,
      "grad_norm": 1.2997921705245972,
      "learning_rate": 1.7765042979942695e-05,
      "loss": 0.0745,
      "step": 320
    },
    {
      "epoch": 321.0,
      "grad_norm": 1.3765255212783813,
      "learning_rate": 1.7191977077363898e-05,
      "loss": 0.0695,
      "step": 321
    },
    {
      "epoch": 322.0,
      "grad_norm": 1.674310326576233,
      "learning_rate": 1.66189111747851e-05,
      "loss": 0.0676,
      "step": 322
    },
    {
      "epoch": 323.0,
      "grad_norm": 1.0994446277618408,
      "learning_rate": 1.6045845272206307e-05,
      "loss": 0.0645,
      "step": 323
    },
    {
      "epoch": 324.0,
      "grad_norm": 1.0698614120483398,
      "learning_rate": 1.5472779369627507e-05,
      "loss": 0.0612,
      "step": 324
    },
    {
      "epoch": 325.0,
      "grad_norm": 1.4865742921829224,
      "learning_rate": 1.4899713467048712e-05,
      "loss": 0.0577,
      "step": 325
    },
    {
      "epoch": 326.0,
      "grad_norm": 0.8876850605010986,
      "learning_rate": 1.4326647564469913e-05,
      "loss": 0.0543,
      "step": 326
    },
    {
      "epoch": 327.0,
      "grad_norm": 0.8850508332252502,
      "learning_rate": 1.3753581661891118e-05,
      "loss": 0.0512,
      "step": 327
    },
    {
      "epoch": 328.0,
      "grad_norm": 0.9629936814308167,
      "learning_rate": 1.3180515759312321e-05,
      "loss": 0.0496,
      "step": 328
    },
    {
      "epoch": 329.0,
      "grad_norm": 0.8929423689842224,
      "learning_rate": 1.2607449856733524e-05,
      "loss": 0.0482,
      "step": 329
    },
    {
      "epoch": 330.0,
      "grad_norm": 0.849876880645752,
      "learning_rate": 1.2034383954154729e-05,
      "loss": 0.0443,
      "step": 330
    },
    {
      "epoch": 331.0,
      "grad_norm": 0.6554436683654785,
      "learning_rate": 1.1461318051575932e-05,
      "loss": 0.0418,
      "step": 331
    },
    {
      "epoch": 332.0,
      "grad_norm": 0.7212005257606506,
      "learning_rate": 1.0888252148997135e-05,
      "loss": 0.0407,
      "step": 332
    },
    {
      "epoch": 333.0,
      "grad_norm": 0.6895676255226135,
      "learning_rate": 1.031518624641834e-05,
      "loss": 0.0404,
      "step": 333
    },
    {
      "epoch": 334.0,
      "grad_norm": 0.9302273392677307,
      "learning_rate": 9.742120343839543e-06,
      "loss": 0.0386,
      "step": 334
    },
    {
      "epoch": 335.0,
      "grad_norm": 0.5761748552322388,
      "learning_rate": 9.169054441260746e-06,
      "loss": 0.0365,
      "step": 335
    },
    {
      "epoch": 336.0,
      "grad_norm": 0.720669150352478,
      "learning_rate": 8.595988538681949e-06,
      "loss": 0.0357,
      "step": 336
    },
    {
      "epoch": 337.0,
      "grad_norm": 0.6463063359260559,
      "learning_rate": 8.022922636103154e-06,
      "loss": 0.036,
      "step": 337
    },
    {
      "epoch": 338.0,
      "grad_norm": 0.6622446179389954,
      "learning_rate": 7.449856733524356e-06,
      "loss": 0.0361,
      "step": 338
    },
    {
      "epoch": 339.0,
      "grad_norm": 0.5624951720237732,
      "learning_rate": 6.876790830945559e-06,
      "loss": 0.035,
      "step": 339
    },
    {
      "epoch": 340.0,
      "grad_norm": 0.5003935098648071,
      "learning_rate": 6.303724928366762e-06,
      "loss": 0.0329,
      "step": 340
    },
    {
      "epoch": 341.0,
      "grad_norm": 0.6838386654853821,
      "learning_rate": 5.730659025787966e-06,
      "loss": 0.0326,
      "step": 341
    },
    {
      "epoch": 342.0,
      "grad_norm": 0.6058831810951233,
      "learning_rate": 5.15759312320917e-06,
      "loss": 0.0338,
      "step": 342
    },
    {
      "epoch": 343.0,
      "grad_norm": 0.5082697868347168,
      "learning_rate": 4.584527220630373e-06,
      "loss": 0.0333,
      "step": 343
    },
    {
      "epoch": 344.0,
      "grad_norm": 0.9971148371696472,
      "learning_rate": 4.011461318051577e-06,
      "loss": 0.0334,
      "step": 344
    },
    {
      "epoch": 345.0,
      "grad_norm": 0.5859812498092651,
      "learning_rate": 3.4383954154727795e-06,
      "loss": 0.033,
      "step": 345
    },
    {
      "epoch": 346.0,
      "grad_norm": 0.7349125146865845,
      "learning_rate": 2.865329512893983e-06,
      "loss": 0.034,
      "step": 346
    },
    {
      "epoch": 347.0,
      "grad_norm": 0.6471587419509888,
      "learning_rate": 2.2922636103151864e-06,
      "loss": 0.0327,
      "step": 347
    },
    {
      "epoch": 348.0,
      "grad_norm": 0.5728564262390137,
      "learning_rate": 1.7191977077363897e-06,
      "loss": 0.032,
      "step": 348
    },
    {
      "epoch": 349.0,
      "grad_norm": 0.5235887169837952,
      "learning_rate": 1.1461318051575932e-06,
      "loss": 0.0309,
      "step": 349
    },
    {
      "epoch": 350.0,
      "grad_norm": 0.5174902677536011,
      "learning_rate": 5.730659025787966e-07,
      "loss": 0.031,
      "step": 350
    },
    {
      "epoch": 351.0,
      "grad_norm": 25.245933532714844,
      "learning_rate": 0.0,
      "loss": 1.0929,
      "step": 351
    },
    {
      "epoch": 352.0,
      "grad_norm": 24.9213924407959,
      "learning_rate": 1.2834224598930484e-05,
      "loss": 1.0948,
      "step": 352
    },
    {
      "epoch": 353.0,
      "grad_norm": 25.121856689453125,
      "learning_rate": 1.2299465240641712e-05,
      "loss": 1.0826,
      "step": 353
    },
    {
      "epoch": 354.0,
      "grad_norm": 25.09263801574707,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 1.0306,
      "step": 354
    },
    {
      "epoch": 355.0,
      "grad_norm": 24.408113479614258,
      "learning_rate": 1.1229946524064172e-05,
      "loss": 0.975,
      "step": 355
    },
    {
      "epoch": 356.0,
      "grad_norm": 24.01615333557129,
      "learning_rate": 1.0695187165775402e-05,
      "loss": 0.9305,
      "step": 356
    },
    {
      "epoch": 357.0,
      "grad_norm": 22.99038314819336,
      "learning_rate": 1.0160427807486631e-05,
      "loss": 0.8652,
      "step": 357
    },
    {
      "epoch": 358.0,
      "grad_norm": 20.689393997192383,
      "learning_rate": 9.625668449197861e-06,
      "loss": 0.8152,
      "step": 358
    },
    {
      "epoch": 359.0,
      "grad_norm": 19.761743545532227,
      "learning_rate": 9.090909090909091e-06,
      "loss": 0.7475,
      "step": 359
    },
    {
      "epoch": 360.0,
      "grad_norm": 19.54344367980957,
      "learning_rate": 8.556149732620321e-06,
      "loss": 0.6999,
      "step": 360
    },
    {
      "epoch": 361.0,
      "grad_norm": 18.296123504638672,
      "learning_rate": 8.02139037433155e-06,
      "loss": 0.6579,
      "step": 361
    },
    {
      "epoch": 362.0,
      "grad_norm": 13.734362602233887,
      "learning_rate": 7.4866310160427806e-06,
      "loss": 0.62,
      "step": 362
    },
    {
      "epoch": 363.0,
      "grad_norm": 13.28899097442627,
      "learning_rate": 6.951871657754011e-06,
      "loss": 0.5802,
      "step": 363
    },
    {
      "epoch": 364.0,
      "grad_norm": 12.96703815460205,
      "learning_rate": 6.417112299465242e-06,
      "loss": 0.565,
      "step": 364
    },
    {
      "epoch": 365.0,
      "grad_norm": 11.854634284973145,
      "learning_rate": 5.882352941176471e-06,
      "loss": 0.5422,
      "step": 365
    },
    {
      "epoch": 366.0,
      "grad_norm": 11.157278060913086,
      "learning_rate": 5.347593582887701e-06,
      "loss": 0.5152,
      "step": 366
    },
    {
      "epoch": 367.0,
      "grad_norm": 12.354969024658203,
      "learning_rate": 4.812834224598931e-06,
      "loss": 0.5157,
      "step": 367
    },
    {
      "epoch": 368.0,
      "grad_norm": 10.522477149963379,
      "learning_rate": 4.2780748663101604e-06,
      "loss": 0.4743,
      "step": 368
    },
    {
      "epoch": 369.0,
      "grad_norm": 10.277097702026367,
      "learning_rate": 3.7433155080213903e-06,
      "loss": 0.4463,
      "step": 369
    },
    {
      "epoch": 370.0,
      "grad_norm": 10.535065650939941,
      "learning_rate": 3.208556149732621e-06,
      "loss": 0.4425,
      "step": 370
    },
    {
      "epoch": 371.0,
      "grad_norm": 9.774048805236816,
      "learning_rate": 2.6737967914438504e-06,
      "loss": 0.4409,
      "step": 371
    },
    {
      "epoch": 372.0,
      "grad_norm": 9.11737060546875,
      "learning_rate": 2.1390374331550802e-06,
      "loss": 0.4199,
      "step": 372
    },
    {
      "epoch": 373.0,
      "grad_norm": 9.959776878356934,
      "learning_rate": 1.6042780748663105e-06,
      "loss": 0.4209,
      "step": 373
    },
    {
      "epoch": 374.0,
      "grad_norm": 10.715113639831543,
      "learning_rate": 1.0695187165775401e-06,
      "loss": 0.4081,
      "step": 374
    },
    {
      "epoch": 375.0,
      "grad_norm": 10.101701736450195,
      "learning_rate": 5.347593582887701e-07,
      "loss": 0.4067,
      "step": 375
    },
    {
      "epoch": 376.0,
      "grad_norm": 19.785675048828125,
      "learning_rate": 0.0,
      "loss": 0.7297,
      "step": 376
    },
    {
      "epoch": 377.0,
      "grad_norm": 21.593647003173828,
      "learning_rate": 1.2030075187969925e-05,
      "loss": 0.7463,
      "step": 377
    },
    {
      "epoch": 378.0,
      "grad_norm": 18.7633056640625,
      "learning_rate": 1.1528822055137844e-05,
      "loss": 0.69,
      "step": 378
    },
    {
      "epoch": 379.0,
      "grad_norm": 17.824050903320312,
      "learning_rate": 1.1027568922305765e-05,
      "loss": 0.6619,
      "step": 379
    },
    {
      "epoch": 380.0,
      "grad_norm": 17.51401710510254,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.63,
      "step": 380
    },
    {
      "epoch": 381.0,
      "grad_norm": 16.79304313659668,
      "learning_rate": 1.0025062656641604e-05,
      "loss": 0.6113,
      "step": 381
    },
    {
      "epoch": 382.0,
      "grad_norm": 14.839422225952148,
      "learning_rate": 9.523809523809523e-06,
      "loss": 0.5544,
      "step": 382
    },
    {
      "epoch": 383.0,
      "grad_norm": 14.180277824401855,
      "learning_rate": 9.022556390977444e-06,
      "loss": 0.5242,
      "step": 383
    },
    {
      "epoch": 384.0,
      "grad_norm": 12.674277305603027,
      "learning_rate": 8.521303258145363e-06,
      "loss": 0.4815,
      "step": 384
    },
    {
      "epoch": 385.0,
      "grad_norm": 12.106744766235352,
      "learning_rate": 8.020050125313283e-06,
      "loss": 0.4563,
      "step": 385
    },
    {
      "epoch": 386.0,
      "grad_norm": 11.754703521728516,
      "learning_rate": 7.518796992481203e-06,
      "loss": 0.4434,
      "step": 386
    },
    {
      "epoch": 387.0,
      "grad_norm": 9.395947456359863,
      "learning_rate": 7.017543859649123e-06,
      "loss": 0.4164,
      "step": 387
    },
    {
      "epoch": 388.0,
      "grad_norm": 9.299046516418457,
      "learning_rate": 6.516290726817042e-06,
      "loss": 0.3952,
      "step": 388
    },
    {
      "epoch": 389.0,
      "grad_norm": 8.589106559753418,
      "learning_rate": 6.015037593984962e-06,
      "loss": 0.386,
      "step": 389
    },
    {
      "epoch": 390.0,
      "grad_norm": 8.52866268157959,
      "learning_rate": 5.5137844611528826e-06,
      "loss": 0.3616,
      "step": 390
    },
    {
      "epoch": 391.0,
      "grad_norm": 8.095163345336914,
      "learning_rate": 5.012531328320802e-06,
      "loss": 0.3583,
      "step": 391
    },
    {
      "epoch": 392.0,
      "grad_norm": 7.795668601989746,
      "learning_rate": 4.511278195488722e-06,
      "loss": 0.3412,
      "step": 392
    },
    {
      "epoch": 393.0,
      "grad_norm": 7.396235466003418,
      "learning_rate": 4.010025062656641e-06,
      "loss": 0.3366,
      "step": 393
    },
    {
      "epoch": 394.0,
      "grad_norm": 7.184676647186279,
      "learning_rate": 3.5087719298245615e-06,
      "loss": 0.3183,
      "step": 394
    },
    {
      "epoch": 395.0,
      "grad_norm": 7.242957592010498,
      "learning_rate": 3.007518796992481e-06,
      "loss": 0.3136,
      "step": 395
    },
    {
      "epoch": 396.0,
      "grad_norm": 7.195976257324219,
      "learning_rate": 2.506265664160401e-06,
      "loss": 0.3057,
      "step": 396
    },
    {
      "epoch": 397.0,
      "grad_norm": 7.396487712860107,
      "learning_rate": 2.0050125313283207e-06,
      "loss": 0.3048,
      "step": 397
    },
    {
      "epoch": 398.0,
      "grad_norm": 7.232321739196777,
      "learning_rate": 1.5037593984962406e-06,
      "loss": 0.2969,
      "step": 398
    },
    {
      "epoch": 399.0,
      "grad_norm": 7.324110984802246,
      "learning_rate": 1.0025062656641603e-06,
      "loss": 0.2929,
      "step": 399
    },
    {
      "epoch": 400.0,
      "grad_norm": 7.610458850860596,
      "learning_rate": 5.012531328320802e-07,
      "loss": 0.2926,
      "step": 400
    },
    {
      "epoch": 401.0,
      "grad_norm": 31.44500160217285,
      "learning_rate": 0.0,
      "loss": 1.1173,
      "step": 401
    },
    {
      "epoch": 402.0,
      "grad_norm": 33.295448303222656,
      "learning_rate": 3.967935871743487e-05,
      "loss": 1.14,
      "step": 402
    },
    {
      "epoch": 403.0,
      "grad_norm": 31.095497131347656,
      "learning_rate": 3.927855711422846e-05,
      "loss": 1.1013,
      "step": 403
    },
    {
      "epoch": 404.0,
      "grad_norm": 26.818296432495117,
      "learning_rate": 3.8877755511022044e-05,
      "loss": 1.0385,
      "step": 404
    },
    {
      "epoch": 405.0,
      "grad_norm": 21.64948844909668,
      "learning_rate": 3.8476953907815634e-05,
      "loss": 0.9531,
      "step": 405
    },
    {
      "epoch": 406.0,
      "grad_norm": 15.01345157623291,
      "learning_rate": 3.807615230460922e-05,
      "loss": 0.8784,
      "step": 406
    },
    {
      "epoch": 407.0,
      "grad_norm": 9.38785457611084,
      "learning_rate": 3.767535070140281e-05,
      "loss": 0.8143,
      "step": 407
    },
    {
      "epoch": 408.0,
      "grad_norm": 6.915274143218994,
      "learning_rate": 3.727454909819639e-05,
      "loss": 0.7844,
      "step": 408
    },
    {
      "epoch": 409.0,
      "grad_norm": 5.370285987854004,
      "learning_rate": 3.687374749498998e-05,
      "loss": 0.7599,
      "step": 409
    },
    {
      "epoch": 410.0,
      "grad_norm": 4.594371318817139,
      "learning_rate": 3.6472945891783566e-05,
      "loss": 0.7367,
      "step": 410
    },
    {
      "epoch": 411.0,
      "grad_norm": 4.489726543426514,
      "learning_rate": 3.6072144288577156e-05,
      "loss": 0.724,
      "step": 411
    },
    {
      "epoch": 412.0,
      "grad_norm": 4.570337772369385,
      "learning_rate": 3.5671342685370746e-05,
      "loss": 0.7114,
      "step": 412
    },
    {
      "epoch": 413.0,
      "grad_norm": 3.9529852867126465,
      "learning_rate": 3.527054108216433e-05,
      "loss": 0.69,
      "step": 413
    },
    {
      "epoch": 414.0,
      "grad_norm": 3.574857473373413,
      "learning_rate": 3.486973947895792e-05,
      "loss": 0.6725,
      "step": 414
    },
    {
      "epoch": 415.0,
      "grad_norm": 3.242534875869751,
      "learning_rate": 3.4468937875751504e-05,
      "loss": 0.6521,
      "step": 415
    },
    {
      "epoch": 416.0,
      "grad_norm": 3.0079123973846436,
      "learning_rate": 3.4068136272545094e-05,
      "loss": 0.6341,
      "step": 416
    },
    {
      "epoch": 417.0,
      "grad_norm": 2.945438861846924,
      "learning_rate": 3.366733466933868e-05,
      "loss": 0.6186,
      "step": 417
    },
    {
      "epoch": 418.0,
      "grad_norm": 2.162759780883789,
      "learning_rate": 3.326653306613227e-05,
      "loss": 0.595,
      "step": 418
    },
    {
      "epoch": 419.0,
      "grad_norm": 2.1341519355773926,
      "learning_rate": 3.286573146292585e-05,
      "loss": 0.582,
      "step": 419
    },
    {
      "epoch": 420.0,
      "grad_norm": 2.3882064819335938,
      "learning_rate": 3.246492985971944e-05,
      "loss": 0.5718,
      "step": 420
    },
    {
      "epoch": 421.0,
      "grad_norm": 2.3389110565185547,
      "learning_rate": 3.2064128256513025e-05,
      "loss": 0.5606,
      "step": 421
    },
    {
      "epoch": 422.0,
      "grad_norm": 2.8409345149993896,
      "learning_rate": 3.1663326653306616e-05,
      "loss": 0.5488,
      "step": 422
    },
    {
      "epoch": 423.0,
      "grad_norm": 2.6087682247161865,
      "learning_rate": 3.12625250501002e-05,
      "loss": 0.5341,
      "step": 423
    },
    {
      "epoch": 424.0,
      "grad_norm": 2.3263962268829346,
      "learning_rate": 3.086172344689379e-05,
      "loss": 0.5219,
      "step": 424
    },
    {
      "epoch": 425.0,
      "grad_norm": 2.103579044342041,
      "learning_rate": 3.046092184368738e-05,
      "loss": 0.5085,
      "step": 425
    },
    {
      "epoch": 426.0,
      "grad_norm": 1.8436754941940308,
      "learning_rate": 3.0060120240480967e-05,
      "loss": 0.4954,
      "step": 426
    },
    {
      "epoch": 427.0,
      "grad_norm": 1.9153361320495605,
      "learning_rate": 2.9659318637274554e-05,
      "loss": 0.4797,
      "step": 427
    },
    {
      "epoch": 428.0,
      "grad_norm": 2.2078192234039307,
      "learning_rate": 2.925851703406814e-05,
      "loss": 0.4676,
      "step": 428
    },
    {
      "epoch": 429.0,
      "grad_norm": 1.9686706066131592,
      "learning_rate": 2.8857715430861727e-05,
      "loss": 0.4541,
      "step": 429
    },
    {
      "epoch": 430.0,
      "grad_norm": 2.0581204891204834,
      "learning_rate": 2.8456913827655314e-05,
      "loss": 0.4397,
      "step": 430
    },
    {
      "epoch": 431.0,
      "grad_norm": 2.0152745246887207,
      "learning_rate": 2.8056112224448898e-05,
      "loss": 0.4299,
      "step": 431
    },
    {
      "epoch": 432.0,
      "grad_norm": 2.0540151596069336,
      "learning_rate": 2.7655310621242485e-05,
      "loss": 0.4166,
      "step": 432
    },
    {
      "epoch": 433.0,
      "grad_norm": 2.71504282951355,
      "learning_rate": 2.7254509018036072e-05,
      "loss": 0.4083,
      "step": 433
    },
    {
      "epoch": 434.0,
      "grad_norm": 3.576268434524536,
      "learning_rate": 2.685370741482966e-05,
      "loss": 0.3968,
      "step": 434
    },
    {
      "epoch": 435.0,
      "grad_norm": 3.179417848587036,
      "learning_rate": 2.6452905811623246e-05,
      "loss": 0.3829,
      "step": 435
    },
    {
      "epoch": 436.0,
      "grad_norm": 3.3323943614959717,
      "learning_rate": 2.6052104208416833e-05,
      "loss": 0.3693,
      "step": 436
    },
    {
      "epoch": 437.0,
      "grad_norm": 2.705695629119873,
      "learning_rate": 2.565130260521042e-05,
      "loss": 0.3571,
      "step": 437
    },
    {
      "epoch": 438.0,
      "grad_norm": 2.539128065109253,
      "learning_rate": 2.5250501002004006e-05,
      "loss": 0.3476,
      "step": 438
    },
    {
      "epoch": 439.0,
      "grad_norm": 2.0764079093933105,
      "learning_rate": 2.4849699398797597e-05,
      "loss": 0.3358,
      "step": 439
    },
    {
      "epoch": 440.0,
      "grad_norm": 2.522947311401367,
      "learning_rate": 2.4448897795591184e-05,
      "loss": 0.3281,
      "step": 440
    },
    {
      "epoch": 441.0,
      "grad_norm": 3.450812578201294,
      "learning_rate": 2.404809619238477e-05,
      "loss": 0.32,
      "step": 441
    },
    {
      "epoch": 442.0,
      "grad_norm": 2.264645576477051,
      "learning_rate": 2.3647294589178358e-05,
      "loss": 0.3072,
      "step": 442
    },
    {
      "epoch": 443.0,
      "grad_norm": 2.5044283866882324,
      "learning_rate": 2.3246492985971944e-05,
      "loss": 0.298,
      "step": 443
    },
    {
      "epoch": 444.0,
      "grad_norm": 2.624814748764038,
      "learning_rate": 2.284569138276553e-05,
      "loss": 0.2885,
      "step": 444
    },
    {
      "epoch": 445.0,
      "grad_norm": 2.8707475662231445,
      "learning_rate": 2.244488977955912e-05,
      "loss": 0.2825,
      "step": 445
    },
    {
      "epoch": 446.0,
      "grad_norm": 2.3228251934051514,
      "learning_rate": 2.2044088176352705e-05,
      "loss": 0.2715,
      "step": 446
    },
    {
      "epoch": 447.0,
      "grad_norm": 1.8288239240646362,
      "learning_rate": 2.1643286573146292e-05,
      "loss": 0.2632,
      "step": 447
    },
    {
      "epoch": 448.0,
      "grad_norm": 2.1528916358947754,
      "learning_rate": 2.124248496993988e-05,
      "loss": 0.2523,
      "step": 448
    },
    {
      "epoch": 449.0,
      "grad_norm": 2.041578531265259,
      "learning_rate": 2.0841683366733466e-05,
      "loss": 0.2462,
      "step": 449
    },
    {
      "epoch": 450.0,
      "grad_norm": 2.034470319747925,
      "learning_rate": 2.0440881763527056e-05,
      "loss": 0.236,
      "step": 450
    },
    {
      "epoch": 451.0,
      "grad_norm": 1.7711597681045532,
      "learning_rate": 2.0040080160320643e-05,
      "loss": 0.2303,
      "step": 451
    },
    {
      "epoch": 452.0,
      "grad_norm": 2.0379726886749268,
      "learning_rate": 1.963927855711423e-05,
      "loss": 0.2215,
      "step": 452
    },
    {
      "epoch": 453.0,
      "grad_norm": 1.98070228099823,
      "learning_rate": 1.9238476953907817e-05,
      "loss": 0.2141,
      "step": 453
    },
    {
      "epoch": 454.0,
      "grad_norm": 2.0728888511657715,
      "learning_rate": 1.8837675350701404e-05,
      "loss": 0.206,
      "step": 454
    },
    {
      "epoch": 455.0,
      "grad_norm": 1.813280701637268,
      "learning_rate": 1.843687374749499e-05,
      "loss": 0.199,
      "step": 455
    },
    {
      "epoch": 456.0,
      "grad_norm": 1.6843169927597046,
      "learning_rate": 1.8036072144288578e-05,
      "loss": 0.1895,
      "step": 456
    },
    {
      "epoch": 457.0,
      "grad_norm": 1.8059730529785156,
      "learning_rate": 1.7635270541082165e-05,
      "loss": 0.1821,
      "step": 457
    },
    {
      "epoch": 458.0,
      "grad_norm": 3.3457517623901367,
      "learning_rate": 1.7234468937875752e-05,
      "loss": 0.179,
      "step": 458
    },
    {
      "epoch": 459.0,
      "grad_norm": 1.5405049324035645,
      "learning_rate": 1.683366733466934e-05,
      "loss": 0.1682,
      "step": 459
    },
    {
      "epoch": 460.0,
      "grad_norm": 1.8634624481201172,
      "learning_rate": 1.6432865731462926e-05,
      "loss": 0.1627,
      "step": 460
    },
    {
      "epoch": 461.0,
      "grad_norm": 1.5841392278671265,
      "learning_rate": 1.6032064128256513e-05,
      "loss": 0.1557,
      "step": 461
    },
    {
      "epoch": 462.0,
      "grad_norm": 1.5873541831970215,
      "learning_rate": 1.56312625250501e-05,
      "loss": 0.1521,
      "step": 462
    },
    {
      "epoch": 463.0,
      "grad_norm": 3.3563523292541504,
      "learning_rate": 1.523046092184369e-05,
      "loss": 0.1495,
      "step": 463
    },
    {
      "epoch": 464.0,
      "grad_norm": 1.9881882667541504,
      "learning_rate": 1.4829659318637277e-05,
      "loss": 0.1421,
      "step": 464
    },
    {
      "epoch": 465.0,
      "grad_norm": 1.6842246055603027,
      "learning_rate": 1.4428857715430864e-05,
      "loss": 0.1389,
      "step": 465
    },
    {
      "epoch": 466.0,
      "grad_norm": 1.862723469734192,
      "learning_rate": 1.4028056112224449e-05,
      "loss": 0.1316,
      "step": 466
    },
    {
      "epoch": 467.0,
      "grad_norm": 1.5992202758789062,
      "learning_rate": 1.3627254509018036e-05,
      "loss": 0.1238,
      "step": 467
    },
    {
      "epoch": 468.0,
      "grad_norm": 2.7768867015838623,
      "learning_rate": 1.3226452905811623e-05,
      "loss": 0.1227,
      "step": 468
    },
    {
      "epoch": 469.0,
      "grad_norm": 1.8645631074905396,
      "learning_rate": 1.282565130260521e-05,
      "loss": 0.1165,
      "step": 469
    },
    {
      "epoch": 470.0,
      "grad_norm": 1.6770883798599243,
      "learning_rate": 1.2424849699398798e-05,
      "loss": 0.1147,
      "step": 470
    },
    {
      "epoch": 471.0,
      "grad_norm": 1.5768107175827026,
      "learning_rate": 1.2024048096192385e-05,
      "loss": 0.11,
      "step": 471
    },
    {
      "epoch": 472.0,
      "grad_norm": 1.2609163522720337,
      "learning_rate": 1.1623246492985972e-05,
      "loss": 0.1068,
      "step": 472
    },
    {
      "epoch": 473.0,
      "grad_norm": 1.6501821279525757,
      "learning_rate": 1.122244488977956e-05,
      "loss": 0.1015,
      "step": 473
    },
    {
      "epoch": 474.0,
      "grad_norm": 1.4165822267532349,
      "learning_rate": 1.0821643286573146e-05,
      "loss": 0.0992,
      "step": 474
    },
    {
      "epoch": 475.0,
      "grad_norm": 1.3135309219360352,
      "learning_rate": 1.0420841683366733e-05,
      "loss": 0.0954,
      "step": 475
    },
    {
      "epoch": 476.0,
      "grad_norm": 4.370776176452637,
      "learning_rate": 1.0020040080160322e-05,
      "loss": 0.1002,
      "step": 476
    },
    {
      "epoch": 477.0,
      "grad_norm": 1.299475908279419,
      "learning_rate": 9.619238476953909e-06,
      "loss": 0.0891,
      "step": 477
    },
    {
      "epoch": 478.0,
      "grad_norm": 1.3259482383728027,
      "learning_rate": 9.218436873747496e-06,
      "loss": 0.0883,
      "step": 478
    },
    {
      "epoch": 479.0,
      "grad_norm": 1.4682717323303223,
      "learning_rate": 8.817635270541082e-06,
      "loss": 0.0862,
      "step": 479
    },
    {
      "epoch": 480.0,
      "grad_norm": 1.379323959350586,
      "learning_rate": 8.41683366733467e-06,
      "loss": 0.0841,
      "step": 480
    },
    {
      "epoch": 481.0,
      "grad_norm": 1.5268189907073975,
      "learning_rate": 8.016032064128256e-06,
      "loss": 0.0823,
      "step": 481
    },
    {
      "epoch": 482.0,
      "grad_norm": 1.2952617406845093,
      "learning_rate": 7.615230460921845e-06,
      "loss": 0.0805,
      "step": 482
    },
    {
      "epoch": 483.0,
      "grad_norm": 1.0817453861236572,
      "learning_rate": 7.214428857715432e-06,
      "loss": 0.0767,
      "step": 483
    },
    {
      "epoch": 484.0,
      "grad_norm": 1.309033751487732,
      "learning_rate": 6.813627254509018e-06,
      "loss": 0.0774,
      "step": 484
    },
    {
      "epoch": 485.0,
      "grad_norm": 1.3575325012207031,
      "learning_rate": 6.412825651302605e-06,
      "loss": 0.0755,
      "step": 485
    },
    {
      "epoch": 486.0,
      "grad_norm": 1.2300796508789062,
      "learning_rate": 6.012024048096193e-06,
      "loss": 0.0751,
      "step": 486
    },
    {
      "epoch": 487.0,
      "grad_norm": 2.1873955726623535,
      "learning_rate": 5.61122244488978e-06,
      "loss": 0.0765,
      "step": 487
    },
    {
      "epoch": 488.0,
      "grad_norm": 1.3972610235214233,
      "learning_rate": 5.2104208416833665e-06,
      "loss": 0.0713,
      "step": 488
    },
    {
      "epoch": 489.0,
      "grad_norm": 1.5606400966644287,
      "learning_rate": 4.809619238476954e-06,
      "loss": 0.0712,
      "step": 489
    },
    {
      "epoch": 490.0,
      "grad_norm": 1.210470199584961,
      "learning_rate": 4.408817635270541e-06,
      "loss": 0.069,
      "step": 490
    },
    {
      "epoch": 491.0,
      "grad_norm": 0.8569015264511108,
      "learning_rate": 4.008016032064128e-06,
      "loss": 0.0678,
      "step": 491
    },
    {
      "epoch": 492.0,
      "grad_norm": 1.0085197687149048,
      "learning_rate": 3.607214428857716e-06,
      "loss": 0.0693,
      "step": 492
    },
    {
      "epoch": 493.0,
      "grad_norm": 0.9339627027511597,
      "learning_rate": 3.2064128256513024e-06,
      "loss": 0.0656,
      "step": 493
    },
    {
      "epoch": 494.0,
      "grad_norm": 1.3353558778762817,
      "learning_rate": 2.80561122244489e-06,
      "loss": 0.069,
      "step": 494
    },
    {
      "epoch": 495.0,
      "grad_norm": 1.135711908340454,
      "learning_rate": 2.404809619238477e-06,
      "loss": 0.0662,
      "step": 495
    },
    {
      "epoch": 496.0,
      "grad_norm": 1.0343071222305298,
      "learning_rate": 2.004008016032064e-06,
      "loss": 0.0645,
      "step": 496
    },
    {
      "epoch": 497.0,
      "grad_norm": 0.9710519909858704,
      "learning_rate": 1.6032064128256512e-06,
      "loss": 0.0674,
      "step": 497
    },
    {
      "epoch": 498.0,
      "grad_norm": 0.9004095196723938,
      "learning_rate": 1.2024048096192386e-06,
      "loss": 0.0648,
      "step": 498
    },
    {
      "epoch": 499.0,
      "grad_norm": 0.9556030035018921,
      "learning_rate": 8.016032064128256e-07,
      "loss": 0.0629,
      "step": 499
    },
    {
      "epoch": 500.0,
      "grad_norm": 1.4657377004623413,
      "learning_rate": 4.008016032064128e-07,
      "loss": 0.0648,
      "step": 500
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 500,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6026508661555200.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
